{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TimeSeries preparation for LSTM\n",
    "This Notebook is embedding the time series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyarrow.parquet as pq\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "import csv\n",
    "#import spacy\n",
    "import multiprocessing\n",
    "import time\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import FastText\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per Patient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_per_patient = pq.read_table('Cohort/Time_Series/all_time_series_woProcedures_timeseries_data_per_patient.parquet').to_pandas()\n",
    "timeseries_per_patient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_LSTM=[]\n",
    "for index, row in timeseries_per_patient.iterrows():\n",
    "    sequence=row['unique_concept']\n",
    "    seq_LSTM.append(sequence[-100:])\n",
    "seq_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_LSTM_pad=tf.keras.preprocessing.sequence.pad_sequences(seq_LSTM, value=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_LSTM_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"Cohort/Time_Series/Timeseries_per_patient_LSTM_Data_raw.txt\", \"wb\") as fp:   #\n",
    "    pickle.dump(seq_LSTM_pad, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Cohort/Time_Series/Timeseries_per_patient_LSTM_Data_raw.txt\", \"rb\") as fp:   # Unpickling\n",
    "    timeseries_per_patient_padded = pickle.load(fp)\n",
    "#timeseries_per_patient_per_day_padded=timeseries_per_patient_per_day_padded#[:3000]\n",
    "timeseries_per_patient_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedd the data with different word2vec embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cbow \n",
    "model_dir = \"Cohort/Time_Series/\"\n",
    "cbow_model0 = Word2Vec.load(model_dir + \"cbow_dim20_win5_mc0.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert int in strings\n",
    "timeseries_per_patient_padded=timeseries_per_patient_padded.astype(str)\n",
    "timeseries_per_patient_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedd all timeseries that have 100 concepts\n",
    "min_concepts=[]\n",
    "timeseries_per_patient_embedded=[]\n",
    "for n in timeseries_per_patient_padded:\n",
    "    try:\n",
    "        t=cbow_model0[n]\n",
    "        timeseries_per_patient_embedded.append(t.tolist())\n",
    "        min_concepts.append('yes')\n",
    "        print('new')\n",
    "        #print(cbow_model0[n])\n",
    "    except: \n",
    "        min_concepts.append('no')\n",
    "        print('padded')\n",
    "len(timeseries_per_patient_embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_concepts\n",
    "mrn_with_min_concept = pq.read_table('Cohort/Time_Series/all_time_series_woProcedures_timeseries_data_per_patient.parquet').to_pandas()\n",
    "mrn_with_min_concept=mrn_with_min_concept.drop('unique_concept', axis=1)\n",
    "mrn_with_min_concept['min_concepts']=min_concepts\n",
    "mrn_with_min_concept=mrn_with_min_concept.loc[mrn_with_min_concept['min_concepts']=='yes']\n",
    "mrn_with_min_concept.to_parquet('Cohort/Time_Series/time_series_per_patient_mrns.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#static dataframe for evaluation \n",
    "static_features=pq.read_table('Cohort/Feature_Extraction/ALL_HF_cohort_unsupervised_only_after_onset_HF_ALL_all_any_all_mean_medium_cleaned_wLab.parquet').to_pandas()\n",
    "static_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mrn_with_min_concept=mrn_with_min_concept.set_index('medical_record_number')\n",
    "time_series_static=pd.merge(static_features, mrn_with_min_concept, left_index=True, right_index=True)\n",
    "time_series_static=time_series_static.drop(['min_concepts'],axis=1)\n",
    "time_series_static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_static.to_parquet('Cohort/Time_Series/time_series_per_patient_static_features.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrn_with_min_concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_per_patient_embedded[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"Cohort/Time_Series/Timeseries_per_patient_LSTM_Data_embedded_cbow_dim20_win5_mc0.txt\", \"wb\") as fp:   #\n",
    "    pickle.dump(timeseries_per_patient_per_day_embedded, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skipgram\n",
    "model_dir = \"Cohort/Time_Series/\"\n",
    "skipgram_model0 = Word2Vec.load(model_dir + \"skipgram_dim20_win5_mc0.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedd all timeseries that have 100 concepts\n",
    "timeseries_per_patient_embedded=[]\n",
    "for n in timeseries_per_patient_per_day_padded:\n",
    "    try:\n",
    "        t=skipgram_model0[n]\n",
    "        timeseries_per_patient_embedded.append(t.tolist())\n",
    "        print('new')\n",
    "        #print(cbow_model0[n])\n",
    "    except: \n",
    "        print('padded')\n",
    "len(timeseries_per_patient_embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_per_patient_embedded[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"Cohort/Time_Series/Timeseries_per_patient_LSTM_Data_embedded_skipgram_dim20_win5_mc0.txt\", \"wb\") as fp:   #\n",
    "    pickle.dump(timeseries_per_patient_embedded, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per Patient Per Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "timeseries_per_patient_per_day = pq.read_table('Cohort/Time_Series/all_time_series_woProcedures_timeseries_data_per_patient_per_day.parquet').to_pandas()\n",
    "timeseries_per_patient_per_day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_per_patient=timeseries_per_patient_per_day['medical_record_number'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(days_per_patient, bins =1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(i < 7 for i in days_per_patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cbow \n",
    "model_dir = \"Cohort/Time_Series/\"\n",
    "cbow_model0 = Word2Vec.load(model_dir + \"cbow_dim20_win5_mc0.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add\n",
    "from operator import truediv\n",
    "cohort_array=[]\n",
    "mrn_in_cohort=[]\n",
    "for mrn in timeseries_per_patient_per_day.medical_record_number.unique():\n",
    "    patient_array=[]\n",
    "    print(mrn)\n",
    "    #get all available days per Patients\n",
    "    patient=timeseries_per_patient_per_day.loc[timeseries_per_patient_per_day.medical_record_number==str(mrn)]\n",
    "    days_count=patient.shape[0]\n",
    "    if days_count >=7:\n",
    "        mrn_in_cohort.append(mrn)\n",
    "        for index, day in patient.iterrows():\n",
    "            #get concepts per day\n",
    "            #print(day['unique_concept'])\n",
    "            seq_day=day['unique_concept']        \n",
    "            conepts_per_day=len(seq_day)\n",
    "            #convert int into strings\n",
    "            seq_day=seq_day.astype(str)\n",
    "            #embedd the concepts: \n",
    "            #emtpy start array: \n",
    "            day_sum=[0]*20\n",
    "            embedded_day=[]\n",
    "            for concept in seq_day:\n",
    "                embedded_day=[]\n",
    "                t=cbow_model0[concept]\n",
    "                embedded_day.append(t.tolist())\n",
    "                #sum of embedded concepts\n",
    "                day_sum=list( map(add, embedded_day[0], day_sum) )\n",
    "            #average of embedded concepts\n",
    "            day_sum=list(map(lambda x: x/conepts_per_day, day_sum))\n",
    "            patient_array.append(day_sum)\n",
    "        cohort_array.append(patient_array[-7:])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mrn_in_cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conepts_per_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_day[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_array[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_array[0][-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cohort_array[1000][7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"Cohort/Time_Series/Timeseries_per_patient_per_day_LSTM_Data_embedded_cbow_dim20_win5_mc0.txt\", \"wb\") as fp:   #\n",
    "    pickle.dump(cohort_array, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Cohort/Time_Series/Timeseries_per_patient_per_day_LSTM_Data_embedded_cbow_dim20_win5_mc0.txt\", \"rb\") as fp:   # Unpickling\n",
    "    timeseries_per_patient_per_day = pickle.load(fp)\n",
    "len(timeseries_per_patient_per_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get static features for per day data \n",
    "static_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_static_per_day=static_features[static_features.index.isin(mrn_in_cohort)]\n",
    "time_series_static_per_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_static_per_day.to_parquet('Cohort/Time_Series/time_series_per_patient_per_day_static_features.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
